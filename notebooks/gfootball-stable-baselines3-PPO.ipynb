{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import base64\n",
    "import pickle\n",
    "import zlib\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from torch import nn, tensor\n",
    "from collections import deque\n",
    "from gym.spaces import Box, Discrete\n",
    "from gfootball.env import create_environment, observation_preprocessing, wrappers\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import CnnPolicy\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv\n",
    "from stable_baselines3.common.policies import BasePolicy, register_policy\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff76d719b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.manual_seed(torch.initial_seed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Football Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "class FootballGym(gym.Env):\n",
    "    spec = None\n",
    "    metadata = None\n",
    "#     metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, config=None, render=False, rewards='scoring'):\n",
    "        super(FootballGym, self).__init__()\n",
    "        env_name = \"academy_empty_goal_close\"\n",
    "        rewards = rewards\n",
    "        if config is not None:\n",
    "            env_name = config.get(\"env_name\", env_name)\n",
    "            rewards = config.get(\"rewards\", rewards)\n",
    "        self.env = create_environment(\n",
    "            env_name=env_name,\n",
    "            stacked=False,\n",
    "            representation=\"simple115v2\",\n",
    "            rewards = rewards,\n",
    "            write_goal_dumps=False,\n",
    "            write_full_episode_dumps=False,\n",
    "            render=render,\n",
    "            write_video=False,\n",
    "            dump_frequency=1,\n",
    "            logdir=\".\",\n",
    "            extra_players=None,\n",
    "            number_of_left_players_agent_controls=1,\n",
    "            number_of_right_players_agent_controls=0)\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.reward_range = (-1, 1)\n",
    "        self.obs_stack = deque([], maxlen=4)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.obs_stack.clear()\n",
    "        obs = self.env.reset()\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step([action])\n",
    "        return obs, float(reward), done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "scenarios = {0: \"academy_empty_goal_close\",\n",
    "             1: \"academy_empty_goal\",\n",
    "             2: \"academy_run_to_score\",\n",
    "             3: \"academy_run_to_score_with_keeper\",\n",
    "             4: \"academy_pass_and_shoot_with_keeper\",\n",
    "             5: \"academy_run_pass_and_shoot_with_keeper\",\n",
    "             6: \"academy_3_vs_1_with_keeper\",\n",
    "             7: \"academy_corner\",\n",
    "             8: \"academy_counterattack_easy\",\n",
    "             9: \"academy_counterattack_hard\",\n",
    "             10: \"academy_single_goal_versus_lazy\",\n",
    "             11: \"11_vs_11_kaggle\",\n",
    "             12: \"11_vs_11_stochastic\",\n",
    "             13: \"11_vs_11_easy_stochastic\",\n",
    "             14: \"11_vs_11_hard_stochastic\"}\n",
    "\n",
    "scenario_name = scenarios[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment creation and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "def make_env(config: dict, rank: int, log_save_dir: str, seed: int = 42) -> Callable:\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :return: (Callable)\n",
    "    \"\"\"\n",
    "    def _init() -> gym.Env:\n",
    "        env = FootballGym(config, rewards='scoring')\n",
    "#         env = FootballGym(config, rewards='scoring,checkpoints')\n",
    "        log_file = os.path.join(log_save_dir, str(rank))\n",
    "        env = Monitor(env, log_file, allow_early_resets=True)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-05-2022-02-25-04\n",
      "Log dir: ../logs/ppo_logs/27-05-2022-02-25-04\n"
     ]
    }
   ],
   "source": [
    "# Creating the vectorized training environmewnt and also creating the direcotry for logging\n",
    "\n",
    "timestamp = time.strftime('%d-%m-%Y-%H-%M-%S', time.localtime())\n",
    "print(timestamp)\n",
    "\n",
    "n_envs = 8\n",
    "config={\"env_name\":scenario_name}\n",
    "log_save_dir = os.path.join(\"../logs/ppo_logs\", timestamp)\n",
    "print(f\"Log dir: {log_save_dir}\")\n",
    "os.mkdir(log_save_dir)\n",
    "train_env = SubprocVecEnv([make_env(config, rank=i, log_save_dir=log_save_dir) for i in range(n_envs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "If you don't want to use dropout, just comment line 198 in torch_layers.py file\n",
      "If you don't want to use dropout, just comment line 198 in torch_layers.py file\n",
      "If you don't want to use dropout, just comment line 198 in torch_layers.py file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential(\n",
       "      (0): Linear(in_features=115, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.25, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.25, inplace=False)\n",
       "      (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=1024, out_features=19, bias=True)\n",
       "  (value_net): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PPO\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    net_arch = [1024, 1024, 1024],\n",
    "    activation_fn = torch.nn.ReLU\n",
    ")\n",
    "\n",
    "# policy_kwargs = dict(features_extractor_class=FootballMLP,\n",
    "#                      features_extractor_kwargs=dict(features_dim=1024),\n",
    "#                     net_arch = [],\n",
    "#                     )\n",
    "model_name = \"ppo\"\n",
    "model = PPO(policy=\"MlpPolicy\", \n",
    "            env=train_env, \n",
    "            seed=0,\n",
    "            n_steps=128, \n",
    "            max_grad_norm=0.5,\n",
    "            gamma=0.99,\n",
    "            ent_coef=0.01,\n",
    "            learning_rate=0.00008,\n",
    "            clip_range=0.27,\n",
    "            policy_kwargs=policy_kwargs, \n",
    "            verbose=1,\n",
    "            tensorboard_log='../logs/tb_logs_PPO',\n",
    "           )\n",
    "model.policy\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mlp_extractor.shared_net.0.weight',\n",
       "              tensor([[-0.0007,  0.0500, -0.0767,  ..., -0.0567,  0.0846,  0.0639],\n",
       "                      [-0.0786, -0.0232,  0.0042,  ..., -0.0265, -0.0313, -0.0138],\n",
       "                      [ 0.0010,  0.0769,  0.0116,  ...,  0.0766,  0.0523, -0.0561],\n",
       "                      ...,\n",
       "                      [ 0.0268,  0.0916,  0.0925,  ...,  0.0530,  0.0869, -0.0264],\n",
       "                      [-0.0562,  0.0565,  0.0287,  ..., -0.0781,  0.0359, -0.0436],\n",
       "                      [-0.0794,  0.0102, -0.0926,  ..., -0.0125,  0.0526, -0.0026]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.0.bias',\n",
       "              tensor([-0.0840, -0.0386, -0.0518,  ..., -0.0873, -0.0291,  0.0105],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.3.weight',\n",
       "              tensor([[-0.0037,  0.0212,  0.0036,  ...,  0.0208, -0.0275,  0.0147],\n",
       "                      [ 0.0037, -0.0189,  0.0156,  ..., -0.0189,  0.0269, -0.0029],\n",
       "                      [-0.0217,  0.0145,  0.0219,  ..., -0.0195,  0.0225, -0.0214],\n",
       "                      ...,\n",
       "                      [ 0.0088, -0.0259, -0.0279,  ...,  0.0308,  0.0246,  0.0205],\n",
       "                      [ 0.0237, -0.0126,  0.0187,  ..., -0.0244, -0.0278,  0.0269],\n",
       "                      [-0.0019,  0.0065,  0.0264,  ...,  0.0183, -0.0051,  0.0212]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.3.bias',\n",
       "              tensor([-0.0157, -0.0310, -0.0090,  ...,  0.0088, -0.0299,  0.0113],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.6.weight',\n",
       "              tensor([[ 0.0108,  0.0182, -0.0050,  ...,  0.0045,  0.0088,  0.0052],\n",
       "                      [ 0.0064, -0.0259, -0.0192,  ...,  0.0106,  0.0211,  0.0305],\n",
       "                      [ 0.0140,  0.0263, -0.0197,  ..., -0.0086, -0.0084, -0.0101],\n",
       "                      ...,\n",
       "                      [ 0.0071,  0.0120, -0.0144,  ..., -0.0092, -0.0228, -0.0148],\n",
       "                      [ 0.0008, -0.0118, -0.0141,  ..., -0.0144, -0.0231,  0.0197],\n",
       "                      [ 0.0117,  0.0087,  0.0081,  ..., -0.0302,  0.0281,  0.0003]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.6.bias',\n",
       "              tensor([-0.0155,  0.0055, -0.0135,  ...,  0.0122, -0.0133,  0.0175],\n",
       "                     device='cuda:0')),\n",
       "             ('action_net.weight',\n",
       "              tensor([[ 0.0144, -0.0235,  0.0075,  ..., -0.0276,  0.0269, -0.0179],\n",
       "                      [ 0.0175,  0.0153,  0.0077,  ...,  0.0112,  0.0083, -0.0307],\n",
       "                      [ 0.0095,  0.0109,  0.0258,  ...,  0.0253, -0.0003, -0.0022],\n",
       "                      ...,\n",
       "                      [-0.0137,  0.0155, -0.0064,  ..., -0.0243,  0.0267, -0.0237],\n",
       "                      [-0.0183,  0.0129, -0.0294,  ..., -0.0135,  0.0187,  0.0281],\n",
       "                      [-0.0247, -0.0007,  0.0150,  ..., -0.0231,  0.0198, -0.0077]],\n",
       "                     device='cuda:0')),\n",
       "             ('action_net.bias',\n",
       "              tensor([-0.0165,  0.0245, -0.0111,  0.0239, -0.0233, -0.0013,  0.0186, -0.0073,\n",
       "                       0.0241,  0.0019,  0.0064,  0.0110,  0.0253,  0.0293,  0.0110,  0.0215,\n",
       "                       0.0259,  0.0179,  0.0096], device='cuda:0')),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-0.0252, -0.0179,  0.0268,  ...,  0.0184, -0.0025, -0.0143]],\n",
       "                     device='cuda:0')),\n",
       "             ('value_net.bias', tensor([0.0308], device='cuda:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading IL agent's weights\n",
    "---\n",
    "Download the checkpoints from here: [IL agent checkpoints](https://drive.google.com/drive/folders/1QwyPsWdGfJMhjEcBIhNot15iij_VRx_U?usp=sharing)\n",
    "\n",
    "Modify the path of the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 147,\n",
       " 'global_step': 479367,\n",
       " 'pytorch-lightning_version': '1.5.10',\n",
       " 'state_dict': OrderedDict([('model.0.weight',\n",
       "               tensor([[-1.2712,  1.7235, -0.8170,  ..., -0.7283, -1.0528, -0.3971],\n",
       "                       [ 0.2426, -0.4846, -0.1319,  ..., -0.3745,  0.1083, -0.1955],\n",
       "                       [ 0.1865, -0.4384,  0.2724,  ...,  0.0148, -0.0946, -0.1312],\n",
       "                       ...,\n",
       "                       [ 0.9357, -2.8718, -1.0750,  ..., -1.5358,  0.2322, -0.8907],\n",
       "                       [ 2.0421, -4.0784, -1.6789,  ..., -0.9545,  0.5744,  0.2149],\n",
       "                       [ 1.1143,  1.9087,  0.0565,  ..., -0.2459, -0.7759, -0.8163]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.0.bias',\n",
       "               tensor([-0.6341, -0.3114, -0.1605,  ..., -0.9393, -2.3791, -0.4585],\n",
       "                      device='cuda:0')),\n",
       "              ('model.3.weight',\n",
       "               tensor([[-1.1699,  0.0614, -0.0255,  ..., -0.2109, -3.2698, -1.0542],\n",
       "                       [ 0.0258, -0.0823, -0.1066,  ..., -0.0416, -0.0200, -0.0641],\n",
       "                       [ 0.7147,  0.0290, -0.0926,  ..., -2.2392, -0.4437, -1.1654],\n",
       "                       ...,\n",
       "                       [-0.8139, -0.3083,  0.0174,  ...,  0.5140,  0.0829, -0.2274],\n",
       "                       [-1.7738, -0.1600, -0.0087,  ...,  2.0135, -1.0897,  1.1122],\n",
       "                       [-3.6944, -0.2209,  0.0721,  ...,  0.6070, -0.5319, -0.3929]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.3.bias',\n",
       "               tensor([-0.9369, -0.3879, -1.3286,  ..., -3.1542, -0.6457, -1.4381],\n",
       "                      device='cuda:0')),\n",
       "              ('model.6.weight',\n",
       "               tensor([[-0.7260, -0.0435, -1.2505,  ..., -0.4365, -1.3087,  0.0558],\n",
       "                       [-0.7509, -0.0897, -0.0494,  ...,  2.2529,  0.5048, -0.2405],\n",
       "                       [-0.2827, -0.0554, -0.1291,  ...,  1.0744, -0.4554,  0.8566],\n",
       "                       ...,\n",
       "                       [-0.6603, -0.0746,  0.0363,  ..., -0.3871,  0.3909, -0.6946],\n",
       "                       [-0.3315, -0.0142, -0.2286,  ..., -0.5628, -0.5618,  0.3244],\n",
       "                       [ 0.3361,  0.0034,  0.3425,  ...,  0.2855,  0.0306, -0.5647]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.6.bias',\n",
       "               tensor([-3.9324, -5.8118, -7.3417,  ..., -5.6045, -6.7020, -5.3817],\n",
       "                      device='cuda:0')),\n",
       "              ('model.9.weight',\n",
       "               tensor([[-4.2259e-01, -2.7937e-03, -3.1767e-01,  ..., -5.3155e-01,\n",
       "                        -1.5168e-01, -1.7476e-01],\n",
       "                       [-2.7354e+00, -1.7560e+00, -3.0881e+00,  ..., -3.7101e+00,\n",
       "                        -3.2042e+00, -1.1286e+00],\n",
       "                       [-1.9991e+00, -1.8066e+00, -1.3018e+00,  ..., -3.2481e+00,\n",
       "                        -3.8814e+00, -2.2249e+00],\n",
       "                       ...,\n",
       "                       [-4.6304e-01, -8.9078e-02, -2.9618e-01,  ..., -3.8560e-01,\n",
       "                        -1.7110e-01, -2.3988e-02],\n",
       "                       [-4.8257e-01, -1.2668e-01, -3.9707e-01,  ..., -3.5611e-01,\n",
       "                        -1.9382e-01, -2.8564e-02],\n",
       "                       [-4.8085e-01, -1.0861e-01, -2.9776e-01,  ..., -4.1145e-01,\n",
       "                        -2.6860e-01, -7.6261e-02]], device='cuda:0')),\n",
       "              ('model.9.bias',\n",
       "               tensor([-1.4722e+01,  4.2186e-02, -6.0975e-02,  1.7896e-01,  3.2716e-01,\n",
       "                        2.3543e-01, -1.7752e-02, -8.5424e-02, -3.1228e-01,  1.0612e-02,\n",
       "                       -1.0615e-01, -6.7585e-01, -3.4433e-01,  9.2337e-02, -1.4248e+01,\n",
       "                       -1.4835e+01, -1.4723e+01, -1.4629e+01, -1.4392e+01], device='cuda:0'))]),\n",
       " 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 10,\n",
       "   'stopped_epoch': 146,\n",
       "   'best_score': tensor(1.3456, device='cuda:0'),\n",
       "   'patience': 10},\n",
       "  \"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/media/ssk/DATA/GRP_code/gr_football_analytics/notebooks/lightning_logs/version_38/checkpoints/epoch=146-step=479366.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/media/ssk/DATA/GRP_code/gr_football_analytics/notebooks/lightning_logs/version_38/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': 479367,\n",
       "     'exp_avg': tensor([[-1.6101e-03,  2.1322e-05, -7.4591e-04,  ...,  1.2841e-10,\n",
       "               5.6052e-45,  9.8378e-07],\n",
       "             [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
       "              -5.6052e-45,  5.6052e-45],\n",
       "             [-5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45, -5.6052e-45],\n",
       "             ...,\n",
       "             [ 5.2331e-04,  1.3445e-06, -1.1211e-04,  ...,  5.2093e-05,\n",
       "               1.6526e-04,  5.6052e-45],\n",
       "             [ 1.1776e-07,  2.8709e-10,  2.5054e-08,  ..., -5.0340e-12,\n",
       "              -5.6052e-45, -5.6052e-45],\n",
       "             [ 4.5729e-03, -5.5788e-05,  1.2405e-03,  ..., -5.6052e-45,\n",
       "               5.6052e-45,  1.2581e-13]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[6.4505e-05, 1.0993e-07, 1.5642e-05,  ..., 6.0872e-10, 1.0172e-14,\n",
       "              3.8651e-08],\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
       "              7.0065e-43],\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
       "              7.0065e-43],\n",
       "             ...,\n",
       "             [1.8585e-05, 2.7495e-10, 2.1706e-06,  ..., 2.0012e-07, 1.3284e-06,\n",
       "              1.0568e-14],\n",
       "             [3.2395e-06, 3.7153e-10, 2.7114e-06,  ..., 2.8595e-06, 2.6465e-12,\n",
       "              7.0065e-43],\n",
       "             [7.7860e-05, 1.5472e-07, 1.3472e-05,  ..., 9.6737e-10, 1.0033e-26,\n",
       "              1.8659e-08]], device='cuda:0')},\n",
       "    1: {'step': 479367,\n",
       "     'exp_avg': tensor([ 1.6341e-03,  5.6052e-45,  5.6052e-45,  ..., -6.4794e-04,\n",
       "             -1.7774e-07, -4.9022e-03], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([7.1683e-05, 7.0065e-43, 7.0065e-43,  ..., 2.3473e-05, 3.3362e-06,\n",
       "             9.4914e-05], device='cuda:0')},\n",
       "    2: {'step': 479367,\n",
       "     'exp_avg': tensor([[ 8.6941e-05,  5.6052e-45,  5.6052e-45,  ..., -3.1256e-07,\n",
       "               6.7410e-14,  3.4018e-05],\n",
       "             [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "              -5.6052e-45,  5.6052e-45],\n",
       "             [-1.2483e-17,  5.6052e-45,  5.6052e-45,  ...,  1.7679e-08,\n",
       "               5.6052e-45, -5.6605e-06],\n",
       "             ...,\n",
       "             [-8.5842e-06, -5.6052e-45,  5.6052e-45,  ..., -7.3801e-06,\n",
       "              -5.6052e-45, -1.2191e-06],\n",
       "             [-1.2059e-05, -5.6052e-45,  5.6052e-45,  ...,  3.1420e-07,\n",
       "               5.6052e-45, -8.5179e-06],\n",
       "             [ 2.0197e-08, -5.6052e-45, -5.6052e-45,  ..., -1.2869e-05,\n",
       "              -5.6052e-45, -1.8529e-05]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.1441e-09, 7.0065e-43, 7.0065e-43,  ..., 2.9100e-09, 2.8453e-11,\n",
       "              9.9118e-09],\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
       "              7.0065e-43],\n",
       "             [1.2363e-10, 7.0065e-43, 7.0065e-43,  ..., 4.6440e-10, 7.0065e-43,\n",
       "              4.9621e-09],\n",
       "             ...,\n",
       "             [6.2078e-09, 7.0065e-43, 7.0065e-43,  ..., 2.7905e-08, 1.5933e-17,\n",
       "              1.9908e-08],\n",
       "             [1.2174e-08, 7.0065e-43, 7.0065e-43,  ..., 2.9987e-09, 2.6329e-13,\n",
       "              4.1563e-08],\n",
       "             [5.0443e-10, 7.0065e-43, 7.0065e-43,  ..., 7.1565e-08, 3.8024e-32,\n",
       "              2.0895e-08]], device='cuda:0')},\n",
       "    3: {'step': 479367,\n",
       "     'exp_avg': tensor([ 1.1584e-04,  5.6052e-45, -2.9805e-05,  ...,  1.0390e-04,\n",
       "              2.1449e-04, -7.8001e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.6480e-06, 7.0065e-43, 8.5246e-07,  ..., 5.4358e-07, 1.2976e-06,\n",
       "             1.9142e-06], device='cuda:0')},\n",
       "    4: {'step': 479367,\n",
       "     'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "               5.6052e-45, -5.6052e-45],\n",
       "             [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "               5.6052e-45, -5.6052e-45],\n",
       "             [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "              -5.6052e-45, -5.6052e-45],\n",
       "             ...,\n",
       "             [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  2.8026e-45,\n",
       "              -5.6052e-45,  5.6052e-45],\n",
       "             [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.0430e-25, 7.0065e-43, 7.0065e-43,  ..., 6.4653e-17, 9.4195e-15,\n",
       "              8.7850e-25],\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 1.2413e-25, 7.0065e-43,\n",
       "              7.0065e-43],\n",
       "             [8.9393e-10, 7.0065e-43, 7.0065e-43,  ..., 3.7023e-23, 3.5276e-31,\n",
       "              7.9332e-13],\n",
       "             ...,\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.4677e-25,\n",
       "              7.0065e-43],\n",
       "             [1.6309e-09, 7.0065e-43, 1.7715e-39,  ..., 6.3506e-09, 7.0065e-43,\n",
       "              1.8728e-37],\n",
       "             [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
       "              7.0065e-43]], device='cuda:0')},\n",
       "    5: {'step': 479367,\n",
       "     'exp_avg': tensor([ 1.5365e-13, -5.6052e-45, -1.9790e-20,  ..., -5.6052e-45,\n",
       "              5.6052e-45, -5.6052e-45], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.4342e-09, 1.4929e-27, 2.3944e-10,  ..., 2.8366e-12, 1.9209e-09,\n",
       "             1.9739e-32], device='cuda:0')},\n",
       "    6: {'step': 479367,\n",
       "     'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             [ 4.7175e-28,  5.6052e-45,  5.7493e-22,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             [ 1.5557e-22,  5.6052e-45, -5.8464e-20,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             ...,\n",
       "             [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45],\n",
       "             [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
       "               5.6052e-45,  5.6052e-45]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.0065e-43, 6.1651e-38, 7.0065e-43,  ..., 1.0015e-41, 6.7874e-22,\n",
       "              7.0065e-43],\n",
       "             [5.9917e-23, 7.0065e-43, 3.2609e-13,  ..., 1.6284e-31, 1.2511e-18,\n",
       "              5.5325e-30],\n",
       "             [8.1109e-20, 7.0065e-43, 6.3047e-09,  ..., 2.2974e-28, 2.9449e-16,\n",
       "              4.3791e-42],\n",
       "             ...,\n",
       "             [7.0065e-43, 1.6356e-25, 7.0065e-43,  ..., 7.0065e-43, 6.5972e-25,\n",
       "              7.0065e-43],\n",
       "             [7.0065e-43, 7.0065e-43, 6.0939e-40,  ..., 7.0065e-43, 3.9420e-22,\n",
       "              7.0065e-43],\n",
       "             [7.0065e-43, 1.5764e-28, 7.0065e-43,  ..., 7.0065e-43, 1.3537e-15,\n",
       "              7.0065e-43]], device='cuda:0')},\n",
       "    7: {'step': 479367,\n",
       "     'exp_avg': tensor([ 5.3712e-13, -4.9893e-03, -2.8806e-03,  7.2319e-03,  3.0017e-03,\n",
       "             -6.5172e-03, -1.0467e-04,  2.4978e-03, -4.6229e-03,  1.1648e-03,\n",
       "             -3.0199e-03,  5.8534e-04,  2.1275e-03,  5.4362e-03,  1.1732e-08,\n",
       "              4.5728e-13,  3.9228e-14,  7.5733e-08,  8.9275e-05], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.5439e-14, 2.7361e-04, 2.1745e-04, 3.0326e-04, 3.7364e-04, 4.3123e-04,\n",
       "             3.0160e-04, 2.3065e-04, 1.8556e-04, 9.9791e-05, 3.7633e-05, 3.9399e-05,\n",
       "             3.6874e-05, 6.1357e-04, 9.3327e-16, 4.1352e-09, 1.5851e-09, 3.2092e-13,\n",
       "             1.5018e-08], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.002,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'hyper_parameters': {'hidden_size': 1024,\n",
       "  'lr': 0.002,\n",
       "  'lr_decay_rate': 0.25,\n",
       "  'batch_size': 256,\n",
       "  'activation': 'ReLU'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IL agent with BN\n",
    "# checkpoint_path = \"../il_agent_checkpoints/epoch=208-step=681548.ckpt\"\n",
    "\n",
    "# IL agent without BN\n",
    "checkpoint_path = \"../il_agent_checkpoints/epoch=146-step=479366.ckpt\"\n",
    "checkpoint_dict = torch.load(checkpoint_path)\n",
    "checkpoint_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mlp_extractor.shared_net.0.weight',\n",
       "              tensor([[-1.2712,  1.7235, -0.8170,  ..., -0.7283, -1.0528, -0.3971],\n",
       "                      [ 0.2426, -0.4846, -0.1319,  ..., -0.3745,  0.1083, -0.1955],\n",
       "                      [ 0.1865, -0.4384,  0.2724,  ...,  0.0148, -0.0946, -0.1312],\n",
       "                      ...,\n",
       "                      [ 0.9357, -2.8718, -1.0750,  ..., -1.5358,  0.2322, -0.8907],\n",
       "                      [ 2.0421, -4.0784, -1.6789,  ..., -0.9545,  0.5744,  0.2149],\n",
       "                      [ 1.1143,  1.9087,  0.0565,  ..., -0.2459, -0.7759, -0.8163]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.0.bias',\n",
       "              tensor([-0.6341, -0.3114, -0.1605,  ..., -0.9393, -2.3791, -0.4585],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.3.weight',\n",
       "              tensor([[-1.1699,  0.0614, -0.0255,  ..., -0.2109, -3.2698, -1.0542],\n",
       "                      [ 0.0258, -0.0823, -0.1066,  ..., -0.0416, -0.0200, -0.0641],\n",
       "                      [ 0.7147,  0.0290, -0.0926,  ..., -2.2392, -0.4437, -1.1654],\n",
       "                      ...,\n",
       "                      [-0.8139, -0.3083,  0.0174,  ...,  0.5140,  0.0829, -0.2274],\n",
       "                      [-1.7738, -0.1600, -0.0087,  ...,  2.0135, -1.0897,  1.1122],\n",
       "                      [-3.6944, -0.2209,  0.0721,  ...,  0.6070, -0.5319, -0.3929]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.3.bias',\n",
       "              tensor([-0.9369, -0.3879, -1.3286,  ..., -3.1542, -0.6457, -1.4381],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.6.weight',\n",
       "              tensor([[-0.7260, -0.0435, -1.2505,  ..., -0.4365, -1.3087,  0.0558],\n",
       "                      [-0.7509, -0.0897, -0.0494,  ...,  2.2529,  0.5048, -0.2405],\n",
       "                      [-0.2827, -0.0554, -0.1291,  ...,  1.0744, -0.4554,  0.8566],\n",
       "                      ...,\n",
       "                      [-0.6603, -0.0746,  0.0363,  ..., -0.3871,  0.3909, -0.6946],\n",
       "                      [-0.3315, -0.0142, -0.2286,  ..., -0.5628, -0.5618,  0.3244],\n",
       "                      [ 0.3361,  0.0034,  0.3425,  ...,  0.2855,  0.0306, -0.5647]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.shared_net.6.bias',\n",
       "              tensor([-3.9324, -5.8118, -7.3417,  ..., -5.6045, -6.7020, -5.3817],\n",
       "                     device='cuda:0')),\n",
       "             ('action_net.weight',\n",
       "              tensor([[-4.2259e-01, -2.7937e-03, -3.1767e-01,  ..., -5.3155e-01,\n",
       "                       -1.5168e-01, -1.7476e-01],\n",
       "                      [-2.7354e+00, -1.7560e+00, -3.0881e+00,  ..., -3.7101e+00,\n",
       "                       -3.2042e+00, -1.1286e+00],\n",
       "                      [-1.9991e+00, -1.8066e+00, -1.3018e+00,  ..., -3.2481e+00,\n",
       "                       -3.8814e+00, -2.2249e+00],\n",
       "                      ...,\n",
       "                      [-4.6304e-01, -8.9078e-02, -2.9618e-01,  ..., -3.8560e-01,\n",
       "                       -1.7110e-01, -2.3988e-02],\n",
       "                      [-4.8257e-01, -1.2668e-01, -3.9707e-01,  ..., -3.5611e-01,\n",
       "                       -1.9382e-01, -2.8564e-02],\n",
       "                      [-4.8085e-01, -1.0861e-01, -2.9776e-01,  ..., -4.1145e-01,\n",
       "                       -2.6860e-01, -7.6261e-02]], device='cuda:0')),\n",
       "             ('action_net.bias',\n",
       "              tensor([-1.4722e+01,  4.2186e-02, -6.0975e-02,  1.7896e-01,  3.2716e-01,\n",
       "                       2.3543e-01, -1.7752e-02, -8.5424e-02, -3.1228e-01,  1.0612e-02,\n",
       "                      -1.0615e-01, -6.7585e-01, -3.4433e-01,  9.2337e-02, -1.4248e+01,\n",
       "                      -1.4835e+01, -1.4723e+01, -1.4629e+01, -1.4392e+01], device='cuda:0')),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-0.0252, -0.0179,  0.0268,  ...,  0.0184, -0.0025, -0.0143]],\n",
       "                     device='cuda:0')),\n",
       "             ('value_net.bias', tensor([0.0308], device='cuda:0'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_keys_toppo_keys_dict = {}\n",
    "sd_ppo_model = model.policy.state_dict()\n",
    "ppo_shared_net_keys = [key for key in model.policy.state_dict().keys() if 'mlp_extractor.shared_net' in key]\n",
    "    \n",
    "mlp_net_keys = ['model.0.weight', 'model.0.bias', 'model.3.weight', 'model.3.bias', 'model.6.weight', 'model.6.bias']\n",
    "for mlp_key, ppo_key in zip(mlp_net_keys, ppo_shared_net_keys):\n",
    "    sd_ppo_model[ppo_key] = checkpoint_dict['state_dict'][mlp_key]\n",
    "\n",
    "sd_ppo_model['action_net.weight'] = checkpoint_dict['state_dict']['model.9.weight']\n",
    "sd_ppo_model['action_net.bias'] = checkpoint_dict['state_dict']['model.9.bias']\n",
    "# sd_ppo_model['value_net.weight'] = checkpoint_dict['state_dict']['model.9.weight']\n",
    "# sd_ppo_model['value_net.bias'] = checkpoint_dict['state_dict']['model.9.bias']\n",
    "\n",
    "    \n",
    "model.policy.load_state_dict(sd_ppo_model)\n",
    "\n",
    "# Check the model's weights after loading the weights from IL agent\n",
    "model.policy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ##### Freezing the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, param in enumerate(model.policy.parameters()):\n",
    "# #     if param.shape == torch.Size([19, 1024]) or param.shape == torch.Size([19]):\n",
    "#     if param.shape == torch.Size([19]):\n",
    "#         print(param.shape, param.requires_grad)\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "#         #     print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, param in enumerate(model.policy.parameters()):\n",
    "# #     param.requires_grad = True\n",
    "#     print(param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class ProgressBar(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(ProgressBar, self).__init__(verbose)\n",
    "        self.pbar = None\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        factor = np.ceil(self.locals['total_timesteps'] / n_steps)\n",
    "        print(f\"self.locals['total_timesteps']:{self.locals['total_timesteps']}, n_steps: {n_steps}\")\n",
    "        n = 1\n",
    "        try:\n",
    "            n = len(self.training_env.envs)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                n = len(self.training_env.remotes)\n",
    "            except AttributeError:\n",
    "                n = 1\n",
    "        total = int(n_steps * factor / n)\n",
    "        self.pbar = tqdm(total=total)\n",
    "\n",
    "    def _on_rollout_start(self):\n",
    "        self.pbar.refresh()\n",
    "\n",
    "    def _on_step(self):\n",
    "        self.pbar.update(1)\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        self.pbar.refresh()\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        self.pbar.close()\n",
    "        self.pbar = None\n",
    "\n",
    "progressbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../logs/tb_logs_PPO/ppo_3\n",
      "self.locals['total_timesteps']:24016, n_steps: 3002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30542a106f64e92ac36ca08f5287dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 359        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24612623 |\n",
      "|    clip_fraction        | 0.564      |\n",
      "|    clip_range           | 0.27       |\n",
      "|    entropy_loss         | -1.68      |\n",
      "|    explained_variance   | -0.0795    |\n",
      "|    learning_rate        | 8e-05      |\n",
      "|    loss                 | 0.127      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.0872     |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 348        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17417833 |\n",
      "|    clip_fraction        | 0.499      |\n",
      "|    clip_range           | 0.27       |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | -0.304     |\n",
      "|    learning_rate        | 8e-05      |\n",
      "|    loss                 | -0.0559    |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.0489     |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 344        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16855453 |\n",
      "|    clip_fraction        | 0.495      |\n",
      "|    clip_range           | 0.27       |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | -2.71      |\n",
      "|    learning_rate        | 8e-05      |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.0394     |\n",
      "|    value_loss           | 0.00334    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 342       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1304516 |\n",
      "|    clip_fraction        | 0.465     |\n",
      "|    clip_range           | 0.27      |\n",
      "|    entropy_loss         | -1.98     |\n",
      "|    explained_variance   | -1.14     |\n",
      "|    learning_rate        | 8e-05     |\n",
      "|    loss                 | -0.0267   |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | 0.0425    |\n",
      "|    value_loss           | 0.000666  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10597934 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.27       |\n",
      "|    entropy_loss         | -1.96      |\n",
      "|    explained_variance   | -1.66      |\n",
      "|    learning_rate        | 8e-05      |\n",
      "|    loss                 | 0.0146     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.0244     |\n",
      "|    value_loss           | 0.000517   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.110058784 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.27        |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | -0.0158     |\n",
      "|    learning_rate        | 8e-05       |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.0061      |\n",
      "|    value_loss           | 0.00821     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090207204 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.27        |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | -2.3        |\n",
      "|    learning_rate        | 8e-05       |\n",
      "|    loss                 | 0.0821      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.0278      |\n",
      "|    value_loss           | 0.000419    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3e+03       |\n",
      "|    ep_rew_mean          | -0.125      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.106785685 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.27        |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 8e-05       |\n",
      "|    loss                 | 0.0571      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0391      |\n",
      "|    value_loss           | 0.000687    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 1\n",
    "n_steps = 3002\n",
    "total_timesteps = n_steps * n_envs * total_epochs\n",
    "model.learn(total_timesteps=total_timesteps, callback=progressbar, log_interval=3, tb_log_name='ppo')\n",
    "\n",
    "saved_model_name = model_name + '_gfootball_' + str(n_envs) + \"_\" + timestamp\n",
    "model.save(f\"../models/{model_name}/{saved_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ../logs/tb_logs_PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the rewards per timestep and per episode\n",
    "\n",
    "plt.style.use(['seaborn-whitegrid'])\n",
    "results_plotter.plot_results([log_save_dir], total_timesteps, results_plotter.X_TIMESTEPS, \"GFootball Timesteps\")\n",
    "# plt.savefig('../figures/dqn/rewards_per_timestamp_dqn_with_my_policy.png')\n",
    "results_plotter.plot_results([log_save_dir], total_timesteps, results_plotter.X_EPISODES, \"GFootball Episodes\")\n",
    "# plt.savefig('../figures/dqn/rewards_per_episode_dqn_with_my_policy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the episodic reward with line\n",
    "\n",
    "x, y = results_plotter.ts2xy(results_plotter.load_results(log_save_dir), 'timesteps')  # Organising the logged results in to a clean format for plotting.\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "plt.plot(x,y)\n",
    "plt.ylim([-10, 10])\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Episode Rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the rolling mean reward per environment\n",
    "\n",
    "plt.style.use(['seaborn-whitegrid'])\n",
    "log_files = [os.path.join(log_save_dir, f\"{i}.monitor.csv\") for i in range(n_envs)]\n",
    "\n",
    "nrows = np.ceil(n_envs/2)\n",
    "fig = plt.figure(figsize=(8, 2 * nrows))\n",
    "for i, log_file in enumerate(log_files):\n",
    "    if os.path.isfile(log_file):\n",
    "        df = pd.read_csv(log_file, skiprows=1)\n",
    "        plt.subplot(nrows, 2, i+1, label=log_file)\n",
    "        df['r'].rolling(window=5).mean().plot(title=f\"Rewards: Env {i}\")\n",
    "        plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean episodic reward\n",
    "# Download the CSV from tensorboard and put the path here\n",
    "df = pd.read_csv('data_for_figures/...')\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "df.plot(x ='Step', y='Value')\n",
    "# plt.savefig('../figures/dqn/mean_ep_reward_with_IL_50_epochs_diff_net.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
