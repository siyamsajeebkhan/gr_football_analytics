{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10a879b",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05082567",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_files_path = '../data/replay_files'\n",
    "replay_files = sorted(os.listdir(replay_files_path))\n",
    "replay_files.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8efe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = replay_files[0]\n",
    "with open(os.path.join(replay_files_path, sample_file), 'rb') as handle:\n",
    "    episode_data = pickle.load(handle)\n",
    "\n",
    "episode = episode_data['observations']\n",
    "# sys.getsizeof(episode_data), sys.getsizeof(episode)\n",
    "episode['ball'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [x for x in range(5)]\n",
    "a_arr = np.array(a, dtype='float32')\n",
    "np.append(a_arr, 6.0, 0)\n",
    "# a_arr.append(6.0)\n",
    "# a_arr[5] = 6.0\n",
    "a_arr\n",
    "# sys.getsizeof(a), a_arr.nbytes, sys.getsizeof(a_arr), a_arr.dtype, a_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565d266",
   "metadata": {},
   "source": [
    "### Create a dataframe with the top replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!!!!!!!!!!!!!!!!!! Do not delete this cell !!!!!!!!!!!!!!!!!!!\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from gfootball.env.wrappers import Simple115StateWrapper\n",
    "import sys\n",
    "# Here we will write the pickle files\n",
    "def prepare_npy_dataset_from_replay_files(replay_files, replay_files_path):\n",
    "    obs_save_dir = '/home/ssk/Study/GRP/dataset/top_480.csv'\n",
    "#     replay_files_path = '../data/replay_files'\n",
    "\n",
    "#     if not os.path.exists(obs_save_dir):\n",
    "#         os.mkdir(obs_save_dir)\n",
    "    replay_dict = {}\n",
    "    for replay in tqdm(replay_files):\n",
    "        with open(os.path.join(replay_files_path, replay), 'rb') as pkl_file:\n",
    "            episode_data = pickle.load(pkl_file)\n",
    "\n",
    "        episode_no = replay.split('.')[0]\n",
    "        episode = episode_data['observations']\n",
    "        episode['active'] = episode_data['players'][0]['active']\n",
    "        episode_length = 3002\n",
    "        raw_obs = {}\n",
    "\n",
    "        episode_dir = os.path.join(obs_save_dir, episode_no)\n",
    "#         if not os.path.exists(episode_dir):\n",
    "#             os.mkdir(episode_dir)\n",
    "\n",
    "        for step in range(episode_length):\n",
    "            for (key, item) in episode.items():\n",
    "                raw_obs[key] = item[step]\n",
    "\n",
    "            float115_frame =  Simple115StateWrapper.convert_observation([raw_obs], True)[0].tolist()\n",
    "            float115_frame_arr = np.array(float115_frame, dtype='float32')\n",
    "            action = episode_data['players'][0]['action'][step]\n",
    "            \n",
    "            frame_name = episode_no+f'_{step}'\n",
    "            if len(action) != 0:\n",
    "                float115_frame.extend(action)\n",
    "                fram_save_path = os.path.join(episode_dir, frame_name)\n",
    "                replay_dict[frame_name] = np.array(float115_frame, dtype='float32')\n",
    "#                 print(f\"Size of the frame list : {sys.getsizeof(float115_frame)} bytes\")\n",
    "#                 print(f\"Size of the numpy array for the same list : {np.array(float115_frame, dtype='float32').nbytes} bytes\")\n",
    "#                 np.save(fram_save_path, np.array(float115_frame))\n",
    "    \n",
    "    a_file = open(\"../data/replay_data.pkl\", \"wb\")\n",
    "    pickle.dump(replay_dict, a_file)\n",
    "    a_file.close()\n",
    "    print(f\"Size of the replay dict for one file: {sys.getsizeof(replay_dict)/1024/1024} MB\")\n",
    "    print(len(replay_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe06aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "replay_files_path = '../data/replay_files'\n",
    "replay_files = sorted(os.listdir(replay_files_path))\n",
    "replay_files.pop(0)\n",
    "# replay_files = replay_files[0:1]\n",
    "print(f\"total replay files: {len(replay_files)}\")\n",
    "# replay_files = replay_files[0:1]\n",
    "\n",
    "start = time.perf_counter()\n",
    "prepare_npy_dataset_from_replay_files(replay_files[0:100], replay_files_path)\n",
    "end =  time.perf_counter()\n",
    "\n",
    "print(f\"Total time needed to process {len(replay_files)}: {end-start}s\")\n",
    "print(f\"Time needed to process a single file: {(end-start)/len(replay_files)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/replay_data.pkl', 'rb') as handle:\n",
    "    loaded_replay_dict = pickle.load(handle)\n",
    "\n",
    "print(f\"Size of the loaded dict: {sys.getsizeof(loaded_replay_dict)/1024/1024} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608aa1c",
   "metadata": {},
   "source": [
    "### Create a dataframe with the top 480 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!!!!!!!!!!!!!!!!!! Do not delete this cell !!!!!!!!!!!!!!!!!!!\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from gfootball.env.wrappers import Simple115StateWrapper\n",
    "\n",
    "# Here we will write the pickle files\n",
    "def prepare_df_with_top_replays(top_replay_df):\n",
    "    obs_save_dir = '/home/ssk/Study/GRP/dataset/top_480.csv'\n",
    "    replay_files_path = '../data/replay_files'\n",
    "    replay_dict = {}\n",
    "    for idx, row in top_replay_df.iterrows():\n",
    "        print(f\"Working on {idx+1}/{480} files\")\n",
    "        episode_no = str(int(row[0]))\n",
    "        episode_file_path = os.path.join(replay_files_path, f\"{episode_no}.p\")\n",
    "        with open(episode_file_path, 'rb') as pkl_file:\n",
    "            episode_data = pickle.load(pkl_file)\n",
    "\n",
    "        episode = episode_data['observations']\n",
    "        episode['active'] = episode_data['players'][0]['active']\n",
    "        episode_length = 3002\n",
    "        raw_obs = {}\n",
    "\n",
    "        for step in range(episode_length):\n",
    "            for (key, item) in episode.items():\n",
    "                raw_obs[key] = item[step]\n",
    "\n",
    "            float115_frame =  Simple115StateWrapper.convert_observation([raw_obs], True)[0].tolist()\n",
    "            float115_frame_arr = np.array(float115_frame, dtype='float32')\n",
    "            action = episode_data['players'][0]['action'][step]\n",
    "            \n",
    "            frame_name = episode_no+f'_{step}'\n",
    "            if len(action) != 0:\n",
    "                float115_frame.extend(action)\n",
    "                replay_dict[frame_name] = np.array(float115_frame, dtype='float32')\n",
    "#                 print(f\"Size of the frame list : {sys.getsizeof(float115_frame)} bytes\")\n",
    "#                 print(f\"Size of the numpy array for the same list : {np.array(float115_frame, dtype='float32').nbytes} bytes\")\n",
    "#                 np.save(fram_save_path, np.array(float115_frame))\n",
    "    \n",
    "    a_file = open(\"../data/top_480_replay_data.pkl\", \"wb\")\n",
    "    pickle.dump(replay_dict, a_file)\n",
    "    a_file.close()\n",
    "    print(f\"Size of the replay dict: {sys.getsizeof(replay_dict)/1024/1024} MB\")\n",
    "#     print(len(replay_dict.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_df = pd.read_csv('../data/top_480_replay_files.csv', header=None)\n",
    "prepare_df_with_top_replays(top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759030b",
   "metadata": {},
   "source": [
    "### Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import logging\n",
    "import os\n",
    "# import time\n",
    "# import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "import csv\n",
    "# import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from tqdm import tqdm\n",
    "# from os.path import join, dirname\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from imitation_learning.dataset.frame_dataset_dict import Float115Dataset\n",
    "from models.mlp_original import MLPModel\n",
    "from utils.solver import Solver\n",
    "# from gfootball.env.wrappers import Simple115StateWrapper\n",
    "from utils.solver import Solver\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pickle\n",
    "# from imitation_learning.dataset.dict_dataset import Float115Dataset as DictDataset\n",
    "# import hydra\n",
    "# import wandb\n",
    "# from omegaconf import DictConfig\n",
    "# import torchtoolbox.transform as transforms\n",
    "# import torchvision\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff621eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seeds for result reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19795b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset containing names of all the frames\n",
    "logging.info(\"Reading the dataset\")\n",
    "with open('../data/top_480_replay_data.pkl', 'rb') as pkl_file:\n",
    "    dict_dataset = pickle.load(pkl_file)\n",
    "    dataset = pd.DataFrame(dict_dataset.keys())\n",
    "#     print(len(dataset))\n",
    "# dataset = pd.read_csv('../data/frames.csv', header=None)[0]\n",
    "logging.info(\"Dataset loaded into the memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train, Val and Test Dataset\n",
    "train, val, test = np.split(dataset.sample(frac=1, random_state=42), [\n",
    "                                    int(.6 * len(dataset)), int(.8 * len(dataset))])\n",
    "train, val, test = train.reset_index(drop=True), \\\n",
    "                                        val.reset_index(drop=True), \\\n",
    "                                        test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f959599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '/home/ssk/Study/GRP/dataset/npy_files'\n",
    "train_dataset, val_dataset, test_dataset = Float115Dataset(train, dict_dataset), \\\n",
    "                                            Float115Dataset(val, dict_dataset), \\\n",
    "                                            Float115Dataset(test, dict_dataset)\n",
    "\n",
    "logging.info(f\"Number of training samples: {len(train_dataset)}\")\n",
    "logging.info(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "logging.info(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d78a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train)\n",
    "del(val)\n",
    "del(test)\n",
    "del(dataset)\n",
    "del(dict_dataset)\n",
    "del(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23df0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e03e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9332b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model and defining different parameters for the training\n",
    "model = MLPModel()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "solver = Solver(model, train_loader, val_loader, criterion, lr, optimizer, writer=writer)\n",
    "solver.train(epochs=10)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067adac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8638e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(solver.train_loss_history, label='train_loss')\n",
    "plt.plot(solver.val_loss_history, label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig('imitation_480.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35966c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c43b6c",
   "metadata": {},
   "source": [
    "### PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2704e6",
   "metadata": {},
   "source": [
    "### Best trial config: {'hidden_size': 512, 'lr': 0.01061546492450981, 'batch_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from models.mlp import MLPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Lightning version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0887f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72583f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {}\n",
    "hparams['hidden_size'] = 512\n",
    "hparams['lr'] = 0.0106\n",
    "hparams['lr_decay_rate'] = 0.25\n",
    "hparams['batch_size'] = 32\n",
    "hparams['activation'] = 'ReLU'\n",
    "model = MLPModel(hparams)\n",
    "model = model.to(device)\n",
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html\n",
    "# trainer = None\n",
    "\n",
    "# from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,\n",
    "# )\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     weights_summary=None,\n",
    "#     profiler=True,\n",
    "#     max_epochs=20,\n",
    "#     gpus=1,\n",
    "#     early_stop_callback=early_stopping,\n",
    "#     check_val_every_n_epoch=1,\n",
    "# )\n",
    "\n",
    "# trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.Util import test_and_save\n",
    "# test_and_save(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921685cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.visualize_predictions(model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fe329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pickle\n",
    "# import sys\n",
    "# with open('/home/ssk/Study/GRP/dataset/top_480_replay_data.pkl', 'rb') as handle:\n",
    "#     data = pickle.load(handle)\n",
    "# print(f\"Size of data: {sys.getsizeof(data)/1024/1024} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f1b70",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from models.mlp import MLPModel\n",
    "from utils.Util import save_model, load_model, test_and_save\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba165c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Callback\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # as explained above, we'll use this callback to collect the validation accuracies\n",
    "    metrics_callback = MetricsCallback()  \n",
    "    \n",
    "    # create a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        #train_percent_check=1.0,\n",
    "        #val_percent_check=1.0,\n",
    "        logger=False,                                                                  # deactivate PL logging\n",
    "        max_epochs=2,                                                                 # epochs\n",
    "        gpus=1 if torch.cuda.is_available() else None,                                 # #gpus\n",
    "#         callbacks=[metrics_callback],                                                  # save latest accuracy\n",
    "#         early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_n_correct\"), # early stopping\n",
    "        early_stop_callback = early_stopping,\n",
    "    )\n",
    "\n",
    "    # here we sample the hyper params, similar as in our old random search\n",
    "#     trial_hparams = {\"hidden_size\": trial.suggest_int(\"hidden_size\", 100, 250, 10),\n",
    "# #                      \"n_layers\": trial.suggest_int(\"n_layers\", 1, 6),\n",
    "# #                      \"dropout_rate\": trial.suggest_loguniform(\"dropout_rate\", 1e-4, 5e-1),\n",
    "#                      \"activation\": trial.suggest_categorical(\"activation\", ('PReLU', 'ReLU', 'LeakyReLU')),\n",
    "#                      \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-1),\n",
    "#                      \"lr_decay_rate\": trial.suggest_loguniform(\"lr_decay_rate\", 1e-1, 5e-1),\n",
    "#                      \"batch_size\": 250}\n",
    "    trial_hparams = {\"activation\": trial.suggest_categorical(\"activation\", ('PReLU', 'ReLU', 'LeakyReLU')),\n",
    "                     \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-1),\n",
    "                     \"lr_decay_rate\": trial.suggest_loguniform(\"lr_decay_rate\", 1e-1, 5e-1),\n",
    "                     \"batch_size\": trial.suggest_int(\"batch_size\", 100, 250, 10)}\n",
    "    \n",
    "    # create model from these hyper params and train it\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "    model = MLPModel(trial_hparams)\n",
    "    model = model.to(device)\n",
    "    model.prepare_data()\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # save model\n",
    "    save_model(model, '{}.p'.format(trial.number), \"checkpoints\")\n",
    "    del(model)\n",
    "    # return validation accuracy from latest model, as that's what we want to minimize by our hyper param search\n",
    "    return metrics_callback.metrics[-1][\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ef672",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da66f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
