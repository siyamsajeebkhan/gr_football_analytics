{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <center> GFootball Stable-Baselines3 </center>\n",
    "\n",
    "---\n",
    "<center><img src=\"https://raw.githubusercontent.com/DLR-RM/stable-baselines3/master/docs/_static/img/logo.png\" width=\"308\" height=\"268\" alt=\"Stable-Baselines3\"></center>\n",
    "<center><small>Image from Stable-Baselines3 repository</small></center>\n",
    "\n",
    "---\n",
    "This notebook uses the [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3) library to train a [PPO](https://openai.com/blog/openai-baselines-ppo/) reinforcement learning agent on [GFootball Academy](https://github.com/google-research/football/tree/master/gfootball/scenarios) scenarios, applying the architecture from the paper \"[Google Research Football: A Novel Reinforcement Learning Environment](https://arxiv.org/abs/1907.11180)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# dependencies\n",
    "apt-get -y update > /dev/null\n",
    "apt-get -y install libsdl2-gfx-dev libsdl2-ttf-dev > /dev/null\n",
    "\n",
    "# cloudpickle, pytorch, gym\n",
    "pip3 install \"cloudpickle==1.3.0\"\n",
    "pip3 install \"torch==1.5.1\"\n",
    "pip3 install \"gym==0.17.2\"\n",
    "\n",
    "# gfootball\n",
    "GRF_VER=v2.8\n",
    "GRF_PATH=football/third_party/gfootball_engine/lib\n",
    "GRF_URL=https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_${GRF_VER}.so\n",
    "git clone -b ${GRF_VER} https://github.com/google-research/football.git\n",
    "mkdir -p ${GRF_PATH}\n",
    "wget -q ${GRF_URL} -O ${GRF_PATH}/prebuilt_gameplayfootball.so\n",
    "cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install . && cd ..\n",
    "\n",
    "# kaggle-environments\n",
    "git clone https://github.com/Kaggle/kaggle-environments.git\n",
    "cd kaggle-environments && pip3 install . && cd ..\n",
    "\n",
    "# stable-baselines3\n",
    "git clone https://github.com/DLR-RM/stable-baselines3.git\n",
    "cd stable-baselines3 && pip3 install . && cd ..\n",
    "\n",
    "# housekeeping\n",
    "rm -rf football kaggle-environments stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!cp \"../input/gfootball-academy/visualizer.py\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import pickle\n",
    "import zlib\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from torch import nn, tensor\n",
    "from collections import deque\n",
    "from gym.spaces import Box, Discrete\n",
    "from kaggle_environments import make\n",
    "from kaggle_environments.envs.football.helpers import *\n",
    "from gfootball.env import create_environment, observation_preprocessing\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import CnnPolicy\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from IPython.display import HTML\n",
    "from visualizer import visualize\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Football Gym\n",
    "> [Stable-Baselines3: Custom Environments](https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html)<br/>\n",
    "> [SEED RL Agent](https://www.kaggle.com/piotrstanczyk/gfootball-train-seed-rl-agent): stacked observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "class FootballGym(gym.Env):\n",
    "    spec = None\n",
    "    metadata = None\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        super(FootballGym, self).__init__()\n",
    "        env_name = \"academy_empty_goal_close\"\n",
    "        rewards = \"scoring,checkpoints\"\n",
    "        if config is not None:\n",
    "            env_name = config.get(\"env_name\", env_name)\n",
    "            rewards = config.get(\"rewards\", rewards)\n",
    "        self.env = create_environment(\n",
    "            env_name=env_name,\n",
    "            stacked=False,\n",
    "            representation=\"raw\",\n",
    "            rewards = rewards,\n",
    "            write_goal_dumps=False,\n",
    "            write_full_episode_dumps=False,\n",
    "            render=False,\n",
    "            write_video=False,\n",
    "            dump_frequency=1,\n",
    "            logdir=\".\",\n",
    "            extra_players=None,\n",
    "            number_of_left_players_agent_controls=1,\n",
    "            number_of_right_players_agent_controls=0)  \n",
    "        self.action_space = Discrete(19)\n",
    "        self.observation_space = Box(low=0, high=255, shape=(72, 96, 16), dtype=np.uint8)\n",
    "        self.reward_range = (-1, 1)\n",
    "        self.obs_stack = deque([], maxlen=4)\n",
    "        \n",
    "    def transform_obs(self, raw_obs):\n",
    "        obs = raw_obs[0]\n",
    "        obs = observation_preprocessing.generate_smm([obs])\n",
    "        if not self.obs_stack:\n",
    "            self.obs_stack.extend([obs] * 4)\n",
    "        else:\n",
    "            self.obs_stack.append(obs)\n",
    "        obs = np.concatenate(list(self.obs_stack), axis=-1)\n",
    "        obs = np.squeeze(obs)\n",
    "        return obs\n",
    "\n",
    "    def reset(self):\n",
    "        self.obs_stack.clear()\n",
    "        obs = self.env.reset()\n",
    "        obs = self.transform_obs(obs)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step([action])\n",
    "        obs = self.transform_obs(obs)\n",
    "        return obs, float(reward), done, info\n",
    "    \n",
    "check_env(env=FootballGym(), warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Football CNN\n",
    "> [Stable-Baselines3: Custom Policy Network](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html)<br/>\n",
    "> [Google Research Football: A Novel Reinforcement Learning Environment](https://arxiv.org/abs/1907.11180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels, stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "    \n",
    "class FootballCNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        in_channels = observation_space.shape[0]  # channels x height x width\n",
    "        self.cnn = nn.Sequential(\n",
    "            conv3x3(in_channels=in_channels, out_channels=32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, dilation=1, ceil_mode=False),\n",
    "            ResidualBlock(in_channels=32, out_channels=32),\n",
    "            ResidualBlock(in_channels=32, out_channels=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "          nn.Linear(in_features=52640, out_features=features_dim, bias=True),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return self.linear(self.cnn(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PPO Model\n",
    "> [Stable-Baselines3: PPO](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)<br/>\n",
    "> [Stable-Baselines3: Vectorized Environments](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html)<br/>\n",
    "> [Stable-Baselines3: Custom Policy Network](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html)<br/>\n",
    "> [GFootball: A Novel Reinforcement Learning Environment](https://arxiv.org/abs/1907.11180)<br/>\n",
    "> [GFootball: Academy Scenarios](https://github.com/google-research/football/tree/master/gfootball/scenarios)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "scenarios = {0: \"academy_empty_goal_close\",\n",
    "             1: \"academy_empty_goal\",\n",
    "             2: \"academy_run_to_score\",\n",
    "             3: \"academy_run_to_score_with_keeper\",\n",
    "             4: \"academy_pass_and_shoot_with_keeper\",\n",
    "             5: \"academy_run_pass_and_shoot_with_keeper\",\n",
    "             6: \"academy_3_vs_1_with_keeper\",\n",
    "             7: \"academy_corner\",\n",
    "             8: \"academy_counterattack_easy\",\n",
    "             9: \"academy_counterattack_hard\",\n",
    "             10: \"academy_single_goal_versus_lazy\",\n",
    "             11: \"11_vs_11_kaggle\"}\n",
    "scenario_name = scenarios[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def make_env(config=None, rank=0):\n",
    "    def _init():\n",
    "        env = FootballGym(config)\n",
    "        log_file = os.path.join(\".\", str(rank))\n",
    "        env = Monitor(env, log_file, allow_early_resets=True)\n",
    "        return env\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = 4\n",
    "config={\"env_name\":scenario_name}\n",
    "train_env = DummyVecEnv([make_env(config, rank=i) for i in range(n_envs)])\n",
    "# train_env = SubprocVecEnv([make_env(config, rank=i) for i in range(n_envs)])\n",
    "\n",
    "n_steps = 512\n",
    "policy_kwargs = dict(features_extractor_class=FootballCNN,\n",
    "                     features_extractor_kwargs=dict(features_dim=256))\n",
    "# model = PPO(CnnPolicy, train_env, \n",
    "#             policy_kwargs=policy_kwargs, \n",
    "#             learning_rate=0.000343, \n",
    "#             n_steps=n_steps, \n",
    "#             batch_size=8, \n",
    "#             n_epochs=2, \n",
    "#             gamma=0.993,\n",
    "#             gae_lambda=0.95,\n",
    "#             clip_range=0.08, \n",
    "#             ent_coef=0.003, \n",
    "#             vf_coef=0.5, \n",
    "#             max_grad_norm=0.64, \n",
    "#             verbose=0)\n",
    "model = PPO.load(\"../input/gfootball-stable-baselines3/ppo_gfootball.zip\", train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training\n",
    "> [Stable-Baselines3: Examples](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html)<br/>\n",
    "> [Stable-Baselines3: Callbacks](https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class ProgressBar(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(ProgressBar, self).__init__(verbose)\n",
    "        self.pbar = None\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        factor = np.ceil(self.locals['total_timesteps'] / self.model.n_steps)\n",
    "        n = 1\n",
    "        try:\n",
    "            n = len(self.training_env.envs)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                n = len(self.training_env.remotes)\n",
    "            except AttributeError:\n",
    "                n = 1\n",
    "        total = int(self.model.n_steps * factor / n)\n",
    "        self.pbar = tqdm(total=total)\n",
    "\n",
    "    def _on_rollout_start(self):\n",
    "        self.pbar.refresh()\n",
    "\n",
    "    def _on_step(self):\n",
    "        self.pbar.update(1)\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        self.pbar.refresh()\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        self.pbar.close()\n",
    "        self.pbar = None\n",
    "\n",
    "progressbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 200\n",
    "total_timesteps = n_steps * n_envs * total_epochs\n",
    "model.learn(total_timesteps=total_timesteps, callback=progressbar)\n",
    "model.save(\"ppo_gfootball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.style.use(['seaborn-whitegrid'])\n",
    "results_plotter.plot_results([\".\"], total_timesteps, results_plotter.X_TIMESTEPS, \"GFootball Timesteps\")\n",
    "results_plotter.plot_results([\".\"], total_timesteps, results_plotter.X_EPISODES, \"GFootball Episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(['seaborn-whitegrid'])\n",
    "log_files = [os.path.join(\".\", f\"{i}.monitor.csv\") for i in range(n_envs)]\n",
    "\n",
    "nrows = np.ceil(n_envs/2)\n",
    "fig = plt.figure(figsize=(8, 2 * nrows))\n",
    "for i, log_file in enumerate(log_files):\n",
    "    if os.path.isfile(log_file):\n",
    "        df = pd.read_csv(log_file, skiprows=1)\n",
    "        plt.subplot(nrows, 2, i+1, label=log_file)\n",
    "        df['r'].rolling(window=100).mean().plot(title=f\"Rewards: Env {i}\")\n",
    "        plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_gfootball\")\n",
    "test_env = FootballGym({\"env_name\":scenario_name})\n",
    "obs = test_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = test_env.step(action)\n",
    "    print(f\"{Action(action).name.ljust(16,' ')}\\t{round(reward,2)}\\t{info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Agent\n",
    "> [Stable-Baselines: Exporting Models](https://stable-baselines.readthedocs.io/en/master/guide/export.html)<br/>\n",
    "> [Stable-Baselines: Converting a Model into PyTorch](https://github.com/hill-a/stable-baselines/issues/372)<br/>\n",
    "> [Connect4: Make Submission with Stable-Baselines3](https://www.kaggle.com/toshikazuwatanabe/connect4-make-submission-with-stable-baselines3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "import base64\n",
    "import pickle\n",
    "import zlib\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch import nn, tensor\n",
    "from collections import deque\n",
    "from gfootball.env import observation_preprocessing\n",
    "\n",
    "state_dict = _STATE_DICT_\n",
    "\n",
    "state_dict = pickle.loads(zlib.decompress(base64.b64decode(state_dict)))\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels, stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "    \n",
    "class PyTorchCnnPolicy(nn.Module):\n",
    "    global state_dict\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            conv3x3(in_channels=16, out_channels=32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, dilation=1, ceil_mode=False),\n",
    "            ResidualBlock(in_channels=32, out_channels=32),\n",
    "            ResidualBlock(in_channels=32, out_channels=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "          nn.Linear(in_features=52640, out_features=256, bias=True),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "        self.action_net = nn.Sequential(\n",
    "          nn.Linear(in_features=256, out_features=19, bias=True),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "        self.out_activ = nn.Softmax(dim=1)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = tensor(x).float() / 255.0  # normalize\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # 1 x channels x height x width\n",
    "        x = self.cnn(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.action_net(x)\n",
    "        x = self.out_activ(x)\n",
    "        return int(x.argmax())\n",
    "    \n",
    "obs_stack = deque([], maxlen=4)\n",
    "def transform_obs(raw_obs):\n",
    "    global obs_stack\n",
    "    obs = raw_obs['players_raw'][0]\n",
    "    obs = observation_preprocessing.generate_smm([obs])\n",
    "    if not obs_stack:\n",
    "        obs_stack.extend([obs] * 4)\n",
    "    else:\n",
    "        obs_stack.append(obs)\n",
    "    obs = np.concatenate(list(obs_stack), axis=-1)\n",
    "    return obs\n",
    "\n",
    "policy = PyTorchCnnPolicy()\n",
    "policy = policy.float().to('cpu').eval()\n",
    "def agent(raw_obs):\n",
    "    obs = transform_obs(raw_obs)\n",
    "    action = policy(obs)\n",
    "    return [action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_gfootball\")\n",
    "_state_dict = model.policy.to('cpu').state_dict()\n",
    "state_dict = {\n",
    "    \"cnn.0.weight\":_state_dict['features_extractor.cnn.0.weight'], \n",
    "    \"cnn.0.bias\":_state_dict['features_extractor.cnn.0.bias'], \n",
    "    \"cnn.2.conv1.weight\":_state_dict['features_extractor.cnn.2.conv1.weight'], \n",
    "    \"cnn.2.conv1.bias\":_state_dict['features_extractor.cnn.2.conv1.bias'],\n",
    "    \"cnn.2.conv2.weight\":_state_dict['features_extractor.cnn.2.conv2.weight'], \n",
    "    \"cnn.2.conv2.bias\":_state_dict['features_extractor.cnn.2.conv2.bias'], \n",
    "    \"cnn.3.conv1.weight\":_state_dict['features_extractor.cnn.3.conv1.weight'], \n",
    "    \"cnn.3.conv1.bias\":_state_dict['features_extractor.cnn.3.conv1.bias'], \n",
    "    \"cnn.3.conv2.weight\":_state_dict['features_extractor.cnn.3.conv2.weight'], \n",
    "    \"cnn.3.conv2.bias\":_state_dict['features_extractor.cnn.3.conv2.bias'], \n",
    "    \"linear.0.weight\":_state_dict['features_extractor.linear.0.weight'], \n",
    "    \"linear.0.bias\":_state_dict['features_extractor.linear.0.bias'], \n",
    "    \"action_net.0.weight\":_state_dict['action_net.weight'],\n",
    "    \"action_net.0.bias\":_state_dict['action_net.bias'],\n",
    "}\n",
    "state_dict = base64.b64encode(zlib.compress(pickle.dumps(state_dict)))\n",
    "with open('submission.py', 'r') as file:\n",
    "    src = file.read()\n",
    "src = src.replace(\"_STATE_DICT_\", f\"{state_dict}\")\n",
    "with open('submission.py', 'w') as file:\n",
    "    file.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "kaggle_env = make(\"football\", debug = False,\n",
    "                  configuration={\"scenario_name\": scenario_name, \n",
    "                                 \"running_in_notebook\": True,\n",
    "                                 \"save_video\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "output = kaggle_env.run([\"submission.py\", \"do_nothing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "scores = output[-1][0][\"observation\"][\"players_raw\"][0][\"score\"]\n",
    "print(\"Scores  {0} : {1}\".format(*scores))\n",
    "print(\"Rewards {0} : {1}\".format(output[-1][0][\"reward\"], output[-1][1][\"reward\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "viz = visualize(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Modified [Human Readable Visualization](https://www.kaggle.com/jaronmichal/human-readable-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "HTML(viz.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Checkpoints\n",
    "\n",
    "0. [academy_empty_goal_close @ 800K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=45569809#Test-Agent) (Nature CNN)<br/>\n",
    "1. [academy_empty_goal @ 800K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=45639135#Test-Agent) (Nature CNN)<br/>\n",
    "2. [academy_run_to_score @ 800K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=45941674#Test-Agent) (Nature CNN)<br/>\n",
    "3. [academy_run_to_score_with_keeper @ 800K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=45703399#Test-Agent) (Nature CNN)<br/>\n",
    "4. [academy_pass_and_shoot_with_keeper @ 800K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=45716494#Test-Agent) (Nature CNN)<br/>\n",
    "5. [academy_run_pass_and_shoot_with_keeper @ 1.6M steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=46590578#Testing) (Nature CNN)<br/>\n",
    "6. [academy_3_vs_1_with_keeper @ 500K steps](https://www.kaggle.com/kwabenantim/gfootball-stable-baselines3?scriptVersionId=46843278#Testing) (GFootball CNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
